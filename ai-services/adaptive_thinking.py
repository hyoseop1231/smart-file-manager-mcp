"""
Adaptive Thinking Algorithm for Smart File Manager
ìë™ ì‚¬ê³  ëª¨ë“œ ì„ íƒ ì‹œìŠ¤í…œ
"""

import re
import logging
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

class ThinkingMode(Enum):
    """ì‚¬ê³  ëª¨ë“œ ì—´ê±°í˜•"""
    THINK_HARD = "think_hard"
    MEGATHINK = "megathink"
    ULTRATHINK = "ultrathink"

@dataclass
class ThinkingAnalysis:
    """ì‚¬ê³  ë¶„ì„ ê²°ê³¼"""
    mode: ThinkingMode
    complexity_score: float
    detected_keywords: List[str]
    estimated_tools: List[str]
    reasoning: str

class AdaptiveThinkingEngine:
    """ì ì‘í˜• ì‚¬ê³  ì—”ì§„"""
    
    def __init__(self):
        # í‚¤ì›Œë“œ ì‚¬ì „ ì •ì˜
        self.megathink_keywords = {
            "ì„¤ê³„": 3, "ì•„í‚¤í…ì²˜": 3, "ì‹œìŠ¤í…œ": 2, "ë³µì¡í•œ": 2, 
            "í†µí•©": 2, "í”„ë¡œì íŠ¸": 2, "ë¶„ì„í•˜ê³ ": 3, "ì„¤ê³„í•˜ê³ ": 3,
            "êµ¬í˜„í•˜ê³ ": 2, "ê°œë°œí•˜ê³ ": 2, "ì°½ì‘": 2, "ì°½ì˜ì ": 2,
            "ë¹„êµ": 2, "ì—¬ëŸ¬": 1, "ë‹¤ì–‘í•œ": 1, "ì¢…í•©": 2
        }
        
        self.ultrathink_keywords = {
            "ì™„ì „ìë™í™”": 5, "ì™„ì „ ìë™í™”": 5, "í’€ìŠ¤íƒ": 4, "full-stack": 4,
            "ì²˜ìŒë¶€í„°ëê¹Œì§€": 4, "ì²˜ìŒë¶€í„° ëê¹Œì§€": 4, "ë°°í¬ê¹Œì§€": 4, "ì™„ë²½í•œ": 3,
            "ìµœì í™”": 3, "ì„±ëŠ¥": 2, "í™•ì¥ì„±": 3, "CI/CD": 4, "DevOps": 4,
            "íŒŒì´í”„ë¼ì¸": 3, "ì¸í”„ë¼": 3, "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤": 4, "ì¿ ë²„ë„¤í‹°ìŠ¤": 3,
            "ë„ì»¤": 2, "í´ë¼ìš°ë“œ": 2, "ì—”í„°í”„ë¼ì´ì¦ˆ": 3, "í”„ë¡œë•ì…˜": 3
        }
        
        # MCP ë„êµ¬ë³„ ë³µì¡ë„ ê°€ì¤‘ì¹˜
        self.mcp_tool_weights = {
            "sequential-thinking": 1,
            "excel": 1, "mermaid": 1, "omnisearch": 1, "youtube": 1,
            "context7": 2, "python-executor": 2, "deep-research": 2,
            "taskmaster-ai": 2, "obsidian": 1, "memory": 1,
            "docker-manager": 3, "k8s-manager": 3, "aws-cli": 3,
            "ssh-control": 2, "git-advanced": 2, "database": 2,
            "playwright": 2, "web-scraper": 2, "slack": 1
        }
        
        # ë©€í‹°ìŠ¤í… íŒ¨í„´
        self.multistep_patterns = [
            r"(\w+)í•˜ê³ \s+(\w+)í•´", r"(\w+)í•´ì„œ\s+(\w+)í•´", 
            r"(\w+)í•œ\s+ë‹¤ìŒ\s+(\w+)í•´", r"(\w+)\s+ê·¸ë¦¬ê³ \s+(\w+)",
            r"(\w+)\s+and\s+(\w+)", r"(\w+),\s+(\w+)",
            r"first\s+(\w+)\s+then\s+(\w+)", r"(\w+)\s+ê·¸ë‹¤ìŒ\s+(\w+)"
        ]

    def analyze_request(self, user_request: str) -> ThinkingAnalysis:
        """ì‚¬ìš©ì ìš”ì²­ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì‚¬ê³  ëª¨ë“œ ê²°ì •"""
        try:
            # 1. í‚¤ì›Œë“œ ë¶„ì„
            keyword_score, detected_keywords = self._analyze_keywords(user_request)
            
            # 2. MCP ë„êµ¬ í•„ìš”ì„± ì¶”ì •
            estimated_tools = self._estimate_required_tools(user_request)
            tool_score = self._calculate_tool_complexity_score(estimated_tools)
            
            # 3. ë©€í‹°ìŠ¤í… ì‘ì—… ê°ì§€
            multistep_score = self._detect_multistep_complexity(user_request)
            
            # 4. ì „ì²´ ë³µì¡ë„ ê³„ì‚°
            complexity_score = self._calculate_total_complexity(
                keyword_score, tool_score, multistep_score, len(estimated_tools)
            )
            
            # 5. ì‚¬ê³  ëª¨ë“œ ê²°ì •
            thinking_mode = self._select_thinking_mode(complexity_score)
            
            # 6. ì¶”ë¡  ì„¤ëª… ìƒì„±
            reasoning = self._generate_reasoning(
                thinking_mode, complexity_score, detected_keywords, 
                estimated_tools, multistep_score
            )
            
            return ThinkingAnalysis(
                mode=thinking_mode,
                complexity_score=complexity_score,
                detected_keywords=detected_keywords,
                estimated_tools=estimated_tools,
                reasoning=reasoning
            )
            
        except Exception as e:
            logger.error(f"Error analyzing request: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ THINK_HARD ë°˜í™˜
            return ThinkingAnalysis(
                mode=ThinkingMode.THINK_HARD,
                complexity_score=1.0,
                detected_keywords=[],
                estimated_tools=[],
                reasoning="Error in analysis, defaulting to basic mode"
            )

    def _analyze_keywords(self, request: str) -> Tuple[float, List[str]]:
        """í‚¤ì›Œë“œ ë¶„ì„ìœ¼ë¡œ ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°"""
        request_lower = request.lower()
        detected_keywords = []
        score = 0
        
        # ULTRATHINK í‚¤ì›Œë“œ ì²´í¬
        for keyword, weight in self.ultrathink_keywords.items():
            if keyword in request_lower:
                detected_keywords.append(f"ultra:{keyword}")
                score += weight
        
        # MEGATHINK í‚¤ì›Œë“œ ì²´í¬
        for keyword, weight in self.megathink_keywords.items():
            if keyword in request_lower:
                detected_keywords.append(f"mega:{keyword}")
                score += weight * 0.7  # ULTRATHINKë³´ë‹¤ ë‚®ì€ ê°€ì¤‘ì¹˜
        
        return score, detected_keywords

    def _estimate_required_tools(self, request: str) -> List[str]:
        """ìš”ì²­ì—ì„œ í•„ìš”í•œ MCP ë„êµ¬ë“¤ ì¶”ì •"""
        request_lower = request.lower()
        estimated_tools = []
        
        # ê¸°ë³¸ì ìœ¼ë¡œ sequential-thinkingì€ í•­ìƒ ì‚¬ìš©
        estimated_tools.append("sequential-thinking")
        
        # ë„êµ¬ë³„ í‚¤ì›Œë“œ ë§¤í•‘
        tool_patterns = {
            "excel": ["ì—‘ì…€", "ìŠ¤í”„ë ˆë“œì‹œíŠ¸", "excel", "spreadsheet", "ë°ì´í„° ë¶„ì„", "ì°¨íŠ¸", "ë°ì´í„°"],
            "mermaid": ["ë‹¤ì´ì–´ê·¸ë¨", "í”Œë¡œìš°ì°¨íŠ¸", "flowchart", "diagram", "ì‹œê°í™”", "ê·¸ë˜í”„", "ì•„í‚¤í…ì²˜"],
            "omnisearch": ["ê²€ìƒ‰", "search", "ì°¾ì•„", "ì¡°ì‚¬", "íŠ¸ë Œë“œ", "ìµœì‹ ", "ì—°êµ¬"],
            "context7": ["ë¼ì´ë¸ŒëŸ¬ë¦¬", "API", "í”„ë ˆì„ì›Œí¬", "ì½”ë”©", "í”„ë¡œê·¸ë˜ë°", "ê°œë°œ", "êµ¬í˜„"],
            "python-executor": ["python", "ì½”ë“œ ì‹¤í–‰", "í…ŒìŠ¤íŠ¸", "ì‹¤í–‰", "íŒŒì´ì¬", "ìŠ¤í¬ë¦½íŠ¸"],
            "docker-manager": ["docker", "ë„ì»¤", "ì»¨í…Œì´ë„ˆ", "container", "ë°°í¬"],
            "k8s-manager": ["kubernetes", "ì¿ ë²„ë„¤í‹°ìŠ¤", "k8s", "í´ëŸ¬ìŠ¤í„°", "ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"],
            "aws-cli": ["aws", "í´ë¼ìš°ë“œ", "ì•„ë§ˆì¡´", "amazon", "ì¸í”„ë¼"],
            "taskmaster-ai": ["ì‘ì—… ê´€ë¦¬", "í”„ë¡œì íŠ¸", "task", "í• ì¼", "ê´€ë¦¬", "ê³„íš"],
            "obsidian": ["ë…¸íŠ¸", "ë¬¸ì„œ", "ì •ë¦¬", "ë©”ëª¨", "ì§€ì‹"],
            "git-advanced": ["git", "ë²„ì „ê´€ë¦¬", "ì»¤ë°‹", "repository", "ì†ŒìŠ¤"],
            "database": ["ë°ì´í„°ë² ì´ìŠ¤", "database", "SQL", "ì¿¼ë¦¬", "ì €ì¥"],
            "playwright": ["ë¸Œë¼ìš°ì €", "ìë™í™”", "í…ŒìŠ¤íŠ¸", "ì›¹", "UI"],
            "deep-research": ["ì—°êµ¬", "ì‹¬í™”", "ë¶„ì„", "ì¡°ì‚¬", "ì •ë³´"],
            "ssh-control": ["SSH", "ì›ê²©", "ì„œë²„", "remote"],
            "web-scraper": ["ìŠ¤í¬ë˜í•‘", "ì›¹ ìˆ˜ì§‘", "í¬ë¡¤ë§", "ë°ì´í„° ìˆ˜ì§‘"]
        }
        
        for tool, keywords in tool_patterns.items():
            if any(keyword in request_lower for keyword in keywords):
                if tool not in estimated_tools:
                    estimated_tools.append(tool)
        
        return estimated_tools

    def _calculate_tool_complexity_score(self, tools: List[str]) -> float:
        """ë„êµ¬ ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°"""
        total_weight = sum(self.mcp_tool_weights.get(tool, 1) for tool in tools)
        return min(total_weight, 10)  # ìµœëŒ€ 10ì 

    def _detect_multistep_complexity(self, request: str) -> float:
        """ë©€í‹°ìŠ¤í… ì‘ì—… ë³µì¡ë„ ê°ì§€"""
        step_count = 0
        
        for pattern in self.multistep_patterns:
            matches = re.findall(pattern, request, re.IGNORECASE)
            step_count += len(matches)
        
        # ë¬¸ì¥ ë¶„ë¦¬ë¡œë„ ë‹¨ê³„ ì¶”ì •
        sentences = re.split(r'[.!?]', request)
        if len(sentences) > 3:
            step_count += len(sentences) - 3
        
        return min(step_count * 1.5, 6)  # ìµœëŒ€ 6ì 

    def _calculate_total_complexity(self, keyword_score: float, tool_score: float, 
                                  multistep_score: float, tool_count: int) -> float:
        """ì „ì²´ ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°"""
        # ê°€ì¤‘ì¹˜ ì ìš©
        keyword_weight = 0.4
        tool_weight = 0.3
        multistep_weight = 0.2
        count_weight = 0.1
        
        total_score = (
            keyword_weight * keyword_score +
            tool_weight * tool_score +
            multistep_weight * multistep_score +
            count_weight * tool_count
        )
        
        return min(total_score, 10)  # 0-10 ë²”ìœ„ë¡œ ì œí•œ

    def _select_thinking_mode(self, complexity_score: float) -> ThinkingMode:
        """ë³µì¡ë„ ì ìˆ˜ì— ë”°ë¥¸ ì‚¬ê³  ëª¨ë“œ ì„ íƒ"""
        if complexity_score >= 6:
            return ThinkingMode.ULTRATHINK
        elif complexity_score >= 3:
            return ThinkingMode.MEGATHINK
        else:
            return ThinkingMode.THINK_HARD

    def _generate_reasoning(self, mode: ThinkingMode, score: float, 
                          keywords: List[str], tools: List[str], 
                          multistep_score: float) -> str:
        """ëª¨ë“œ ì„ íƒ ì´ìœ  ì„¤ëª… ìƒì„±"""
        reasoning_parts = [
            f"ë³µì¡ë„ ì ìˆ˜: {score:.1f}/10",
            f"ì„ íƒëœ ëª¨ë“œ: {mode.value.upper()}"
        ]
        
        if keywords:
            reasoning_parts.append(f"ê°ì§€ëœ í‚¤ì›Œë“œ: {', '.join(keywords)}")
        
        if len(tools) > 1:
            reasoning_parts.append(f"ì˜ˆìƒ ë„êµ¬ ({len(tools)}ê°œ): {', '.join(tools)}")
        
        if multistep_score > 2:
            reasoning_parts.append(f"ë©€í‹°ìŠ¤í… ì‘ì—… ê°ì§€: {multistep_score:.1f}ì ")
        
        return " | ".join(reasoning_parts)

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_thinking_engine = None

def get_adaptive_thinking_engine() -> AdaptiveThinkingEngine:
    """ì ì‘í˜• ì‚¬ê³  ì—”ì§„ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _thinking_engine
    if _thinking_engine is None:
        _thinking_engine = AdaptiveThinkingEngine()
    return _thinking_engine

def analyze_and_suggest_mode(user_request: str) -> ThinkingAnalysis:
    """ì‚¬ìš©ì ìš”ì²­ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì‚¬ê³  ëª¨ë“œ ì œì•ˆ"""
    engine = get_adaptive_thinking_engine()
    return engine.analyze_request(user_request)

def format_thinking_mode_display(analysis: ThinkingAnalysis) -> str:
    """ì‚¬ê³  ëª¨ë“œ í‘œì‹œìš© í¬ë§·íŒ…"""
    mode_icons = {
        ThinkingMode.THINK_HARD: "ğŸ”®",
        ThinkingMode.MEGATHINK: "âœ¨", 
        ThinkingMode.ULTRATHINK: "ğŸ’"
    }
    
    icon = mode_icons.get(analysis.mode, "ğŸ”®")
    
    return f"""
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ {icon} {analysis.mode.value.upper()} Mode Activated â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ {analysis.reasoning}
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
"""

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
def test_thinking_modes():
    """ì‚¬ê³  ëª¨ë“œ í…ŒìŠ¤íŠ¸"""
    test_cases = [
        "Python í•¨ìˆ˜ ë§Œë“¤ì–´ì¤˜",
        "ì›¹ì‚¬ì´íŠ¸ ì„¤ê³„í•˜ê³  êµ¬í˜„í•´ì¤˜",
        "í’€ìŠ¤íƒ ì•±ì„ ì²˜ìŒë¶€í„° ë°°í¬ê¹Œì§€ ì™„ì „ ìë™í™”í•´ì¤˜",
        "ë°ì´í„° ë¶„ì„í•˜ê³  ì‹œê°í™”í•´ì¤˜",
        "ë³µì¡í•œ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì œì•ˆí•´ì¤˜",
        "Dockerì™€ ì¿ ë²„ë„¤í‹°ìŠ¤ë¡œ CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•í•´ì¤˜"
    ]
    
    for request in test_cases:
        analysis = analyze_and_suggest_mode(request)
        print(f"\nìš”ì²­: {request}")
        print(format_thinking_mode_display(analysis))

if __name__ == "__main__":
    test_thinking_modes()